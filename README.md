üìä Calculadora de M√©tricas de Avalia√ß√£o para Modelos de Classifica√ß√£o
üìñ Descri√ß√£o
Este projeto consiste na implementa√ß√£o manual em Python das principais m√©tricas de avalia√ß√£o para modelos de classifica√ß√£o bin√°ria: Acur√°cia, Sensibilidade (Recall), Especificidade, Precis√£o e F1-Score. O objetivo √© aprofundar o entendimento sobre o funcionamento de cada m√©trica a partir de valores de uma Matriz de Confus√£o definidos arbitrariamente.

Adicionalmente, o projeto inclui a visualiza√ß√£o da Matriz de Confus√£o utilizando as bibliotecas Matplotlib e Seaborn para uma interpreta√ß√£o mais clara e intuitiva dos resultados.

üöÄ Contexto
Este √© um dos desafios de projeto propostos no Bootcamp Machine Learning Training, uma parceria entre a Digital Innovation One (DIO) e a BairesDev.

üõ†Ô∏è Tecnologias Utilizadas
Linguagem: Python 3

Ambiente: Google Colab / Jupyter Notebook

Bibliotecas:

NumPy: Para a estrutura√ß√£o da matriz de confus√£o.

Matplotlib: Para a cria√ß√£o da base dos gr√°ficos.

Seaborn: Para a visualiza√ß√£o elegante da matriz de confus√£o (heatmap).

üìÇ Estrutura do Projeto
O projeto √© inteiramente contido no notebook Jupyter:

calculo_metricas.ipynb: Notebook contendo todo o processo, desde a defini√ß√£o do cen√°rio, implementa√ß√£o das fun√ß√µes, c√°lculo dos resultados e a an√°lise final.

‚ñ∂Ô∏è Como Executar
Clone este reposit√≥rio para sua m√°quina local ou baixe o arquivo .ipynb.

Abra o notebook calculo_metricas.ipynb no Google Colab ou em um ambiente Jupyter local.

Execute as c√©lulas de c√≥digo em ordem sequencial.

üìà Resultados
Para o cen√°rio de teste definido com os seguintes valores:

Verdadeiros Positivos (VP): 150

Verdadeiros Negativos (VN): 120

Falsos Positivos (FP): 80

Falsos Negativos (FN): 60

As m√©tricas de avalia√ß√£o calculadas foram:

M√©trica

Resultado

Acur√°cia

0.659

Sensibilidade (Recall)

0.714

Especificidade

0.600

Precis√£o

0.652

F1-Score

0.682

Matriz de Confus√£o
A visualiza√ß√£o da Matriz de Confus√£o para o cen√°rio acima √© a seguinte:

![Matriz de Confus√£o](nome_da_sua_imagem.png)

Nota: Para que a imagem apare√ßa, tire um print do seu gr√°fico, salve o arquivo (ex: matriz_confusao.png) na mesma pasta do projeto no GitHub e certifique-se que o nome no c√≥digo acima corresponde ao nome do seu arquivo.

üß† An√°lise e Conclus√£o
A an√°lise das m√©tricas revela um desempenho moderado do modelo hipot√©tico. A Acur√°cia de 65.9% indica que o modelo acerta mais do que erra, mas est√° longe de ser altamente confi√°vel.

O ponto mais interessante √© a rela√ß√£o entre Precis√£o (65.2%) e Sensibilidade (71.4%). A sensibilidade ser maior indica que o modelo tem uma capacidade relativamente melhor de identificar corretamente os casos positivos (encontrar os "spams", em nosso exemplo) do que de garantir que, quando ele classifica um caso como positivo, ele de fato seja (evitar "alarmes falsos").

O ponto mais fraco do modelo √© a Especificidade (60.0%), mostrando uma dificuldade consider√°vel em identificar corretamente os casos negativos. Em um cen√°rio de filtro de spam, isso significaria que uma quantidade relevante de e-mails leg√≠timos seria classificada incorretamente como spam (Falsos Positivos).

Conclus√£o: Baseado nesta an√°lise, o modelo n√£o seria recomendado para um ambiente de produ√ß√£o sem melhorias significativas. A baixa especificidade, em particular, geraria uma experi√™ncia negativa para o usu√°rio. Pr√≥ximos passos incluiriam a utiliza√ß√£o de t√©cnicas de otimiza√ß√£o ou a escolha de um algoritmo mais robusto para tentar aumentar a capacidade do modelo de discernir entre as classes, especialmente os casos negativos.

‚úçÔ∏è Autor
Johnny Passos

üìÑ Licen√ßa
Este projeto est√° sob a licen√ßa MIT.
